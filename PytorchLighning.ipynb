{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598efe69-e1ac-4d8b-8f68-7b9ca3296d48",
   "metadata": {},
   "source": [
    "### Import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbee486-db65-4756-b8db-1f7e2a1ed32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torchmetrics\n",
    "\n",
    "import re\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fc0ceb-e09c-4c48-8ed9-99480bac9477",
   "metadata": {},
   "source": [
    "## Importation des données et du tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954ff50-0cf1-436c-a03e-07ad01a005ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('DATA/X_train.csv').set_index('ID').join(\n",
    "    pd.read_csv('DATA/y_train.csv').set_index('ID'))\n",
    "# X = pd.read_csv('xxx.csv')\n",
    "# X.question = [re.sub('[^a-zA-Z ]','',x) for x in X.question]\n",
    "# X.question=X.question.apply(str.lower)\n",
    "# X.question= [x.replace('  ',' ') for x in X.question]\n",
    "\n",
    "test =  pd.read_csv('DATA/test.csv').set_index('ID')\n",
    "\n",
    "num_labels = X.intention.unique().shape[0]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('camembert-base',max_lenght=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b54e21-921e-43a7-939c-28def5a25ec7",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7050bb7-8e14-423d-ab37-d1392474039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(samples, tokenizer):\n",
    "    text = [sample[\"question\"] for sample in samples]\n",
    "    labels = torch.tensor([sample[\"intention\"] for sample in samples])\n",
    "    tokens = tokenizer(text, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    return {\"input_ids\": tokens.input_ids, \"attention_mask\": tokens.attention_mask, \"labels\": labels,\"sentences\": text}\n",
    "\n",
    "X['len']=list(map(len,X.question.str.split()))\n",
    "\n",
    "\n",
    "X=X.loc[X.len<250]\n",
    "X=X.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b2b34f-aff7-4575-a816-67d181bc26cb",
   "metadata": {},
   "source": [
    "#### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dc124-01ae-46c2-a4e3-0f117cd3cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug=back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='Helsinki-NLP/opus-mt-fr-en', \n",
    "    to_model_name='Helsinki-NLP/opus-mt-en-fr'\n",
    ")\n",
    "aug2 = naw.BackTranslationAug(\n",
    "    from_model_name='Helsinki-NLP/opus-mt-fr-ru', \n",
    "    to_model_name='Helsinki-NLP/opus-mt-ru-fr'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0027b5f-0a69-484d-8ea3-693b22607689",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    X[:6000].to_dict(orient='record'), \n",
    "    batch_size=8,\n",
    "    shuffle=True, \n",
    "    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer),\n",
    "    Transforms=None,\n",
    "    num_workers=4\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    X[6000:].to_dict(orient='record'), \n",
    "    batch_size=8, \n",
    "    shuffle=False, \n",
    "    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer),\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe56501-adac-4d02-aa86-71ecf3aed740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(self, model_name, num_labels, lr, weight_decay, from_scratch=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if from_scratch:\n",
    "            # Si `from_scratch` est vrai, on charge uniquement la config (nombre de couches, hidden size, etc.) et pas les poids du modèle \n",
    "            config = AutoConfig.from_pretrained(\n",
    "                model_name, num_labels=num_labels\n",
    "            )\n",
    "            self.model = AutoModelForSequenceClassification.from_config(config)\n",
    "        else:\n",
    "            # Cette méthode permet de télécharger le bon modèle pré-entraîné directement depuis le Hub de HuggingFace sur lequel sont stockés de nombreux modèles\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                model_name, num_labels=num_labels\n",
    "            )\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.num_labels = self.model.num_labels\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"]\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        logits = out.logits\n",
    "        # -------- MASKED --------\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(logits.view(-1, self.num_labels), batch[\"labels\"].view(-1))\n",
    "\n",
    "        # ------ END MASKED ------\n",
    "        \n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        labels = batch[\"labels\"]\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        preds = torch.max(out.logits, -1).indices\n",
    "        # -------- MASKED --------\n",
    "        acc = (batch[\"labels\"] == preds).float().mean()\n",
    "        # ------ END MASKED ------\n",
    "        self.log(\"valid/acc\", acc)\n",
    "\n",
    "        f1 = f1_score(batch[\"labels\"].cpu().tolist(), preds.cpu().tolist(), average=\"macro\")\n",
    "        self.log(\"valid/f1\", f1)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        \"\"\"La fonction predict step facilite la prédiction de données. Elle est \n",
    "        similaire à `validation_step`, sans le calcul des métriques.\n",
    "        \"\"\"\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        return torch.max(out.logits, -1).indices\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(\n",
    "            self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb0cc9-7e2b-43bf-a2b4-e3ac94e6eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = LightningModel(\"camembert-base\", num_labels, lr=3e-5, weight_decay=0.,from_scratch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0600a6-0ad1-4bc6-a4ef-7877703d7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfeefd4-5ecf-455e-a07e-93db49ce4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir lightning_logs --host localhost --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228d985-42b7-47e9-82dc-e1b9dbb6abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"valid/acc\", mode=\"max\")\n",
    "\n",
    "camembert_trainer = pl.Trainer(\n",
    "    max_epochs=40,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor=\"valid/acc\", patience=4, mode=\"max\"),\n",
    "        model_checkpoint,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b97287-8649-47de-8fc0-bb804068f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "camembert_trainer.fit(lightning_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b914fa-a1c0-472a-bc2d-72f550062930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, tokenizer, sentence):\n",
    "    tokenized_sentence = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    input_ids, attention_mask = tokenized_sentence.input_ids, tokenized_sentence.attention_mask\n",
    "\n",
    "    out = model(tokenized_sentence\n",
    "    )\n",
    "\n",
    "    logits = out.logits\n",
    "\n",
    "    probas = torch.softmax(logits, -1).squeeze()\n",
    "\n",
    "    pred = torch.argmax(probas)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c79faa-858a-480a-8121-7a85a387a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['intention'] = [get_preds(lightning_model,tokenizer,i).to().numpy() for i in test.question]\n",
    "test['intention'].to_csv('resultat.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
